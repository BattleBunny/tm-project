{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from typing import Literal, List\n",
    "import re\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first load data, get all years together\n",
    "what is devtest???\n",
    "\n",
    "ik doe wat ze in paper hebben gedaan (alle data van vorige jaren = train,+ train van dit jaar), maar toch is er evenveel test als train ongeveer, wat ik raar vind.) het lijkt alsof er minder train dan test data is ook (bijv 2015) -> dat is toch raar hahah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(dataset: Literal[\"train\",\"test\"], path=\"data/downloaded/\") -> List[str]:\n",
    "    if dataset == \"train\":\n",
    "        r = '[a-z]+-(\\d{4})'\n",
    "        onlyfiles = [f for f in os.listdir(\"data/downloaded\") if os.path.isfile(os.path.join(\"data/downloaded\", f)) and os.path.join(\"data/downloaded\", f)[-5] == \"A\"]\n",
    "        return [f for f in onlyfiles if f not in [\"twitter-2016dev-A.tsv\", \"twitter-2016devtest-A.tsv\", \"twitter-2016train-A.tsv\"]]\n",
    "    return [\"twitter-2016dev-A.tsv\", \"twitter-2016devtest-A.tsv\", \"twitter-2016train-A.tsv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_data(dataset: Literal[\"train\",\"test\"], path=\"data/downloaded/\") -> None:\n",
    "    # write all data from previous years to new file, as in paper\n",
    "    filenames = get_filenames(dataset, path=path)\n",
    "\n",
    "    with open(f'{path}twitter-{dataset}.tsv','w', encoding=\"utf-8\") as outfile:\n",
    "        for fname in filenames:\n",
    "            with open(path+fname, \"r\",encoding=\"utf-8\") as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(\"train\")\n",
    "concatenate_data(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 80%, test: 20%\n",
      "train: 40297, test: 9834\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/downloaded/twitter-train.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"])\n",
    "test = pd.read_csv(\"data/downloaded/twitter-test.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"])\n",
    "# dev = pd.read_csv(\"data/downloaded/twitter-2016dev-A.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"])\n",
    "\n",
    "print(f\"train: {round(train.shape[0]/(train.shape[0]+test.shape[0])*100)}%, test: {round(test.shape[0]/(train.shape[0]+test.shape[0])*100)}%\")\n",
    "print(f\"train: {train.shape[0]}, test: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Theo Walcott is still shit\\\\u002c watch Rafa and Johnny deal with him on Saturday.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.text = train.text.astype('unicode')\n",
    "train.text[20632].encode(\"ascii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6243</td>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19096</td>\n",
       "      <td>3428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>14958</td>\n",
       "      <td>4840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "label                \n",
       "negative   6243  1566\n",
       "neutral   19096  3428\n",
       "positive  14958  4840"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_counts = train.groupby('label').count().rename({\"text\":\"train\"}, axis=1)\n",
    "test_class_counts = test.groupby('label').count().rename({\"text\":\"test\"}, axis=1)\n",
    "# dev_class_counts = dev.groupby('label').count().rename({\"text\":\"dev\"}, axis=1)\n",
    "\n",
    "#TODO we moeten nog dev hebben: 80/20 split van tex\n",
    "\n",
    "\n",
    "pd.concat([train_class_counts, test_class_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing:\n",
    "remove links? \n",
    "remove @'s ?\n",
    "punctuation etc? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0   neutral  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
       "1   neutral  Order Go Set a Watchman in store or through ou...\n",
       "2  negative  If these runway renovations at the airport pre...\n",
       "3   neutral  If you could ask an onstage interview question...\n",
       "4  positive  A portion of book sales from our Harper Lee/Go..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing:\n",
    "\n",
    "def preprocess(data: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "        \n",
    "    # remove urls\n",
    "    data_clean = data.copy()\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'https?:\\/\\/\\S+','',x))\n",
    "\n",
    "    # remove emailadresses\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'\\w+@\\w+\\.[a-z]+','',x))\n",
    "\n",
    "    # remove html ref\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'&amp', '&', x))\n",
    "\n",
    "    # remove unicode\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'\\\\u[a-z0-9]{4}', '', x))\n",
    "\n",
    "    # remove all @ mention\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "\n",
    "    # remove non-letter characters, numbers \n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"[^a-zA-Z\\s\\:\\];='\\.\\!\\?\\,]\", ' ', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])st([.,!?\\s])\", ' ', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])th([.,!?\\s])\", ' ', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])nd([.,!?\\s])\", ' ', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])rd([.,!?\\s])\", ' ', x))\n",
    "\n",
    "\n",
    "    # remove trailing whitespace\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "    data_clean.to_csv(f\"data/downloaded/twitter-{name}-clean.tsv\", sep=\"\\t\", index=False,header=False,encoding=\"utf-8\")\n",
    "\n",
    "    return data_clean\n",
    "# overige dingen: afkortingen? getallen kunnen belangrijk zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = preprocess(train, \"train\")\n",
    "test_cleaned = preprocess(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment: probeer de verschillende instellingen aangeraden door autheurs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7b48cf7c021d35b2fd1684e6f7d2f969b0897b100551e75462f6bc010a51b9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tmprojectenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
