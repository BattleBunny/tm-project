{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import codecs\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from typing import Literal, List\n",
    "import re\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(dataset: Literal[\"train\",\"test\"], path=\"data/downloaded/\") -> List[str]:\n",
    "    if dataset == \"train\":\n",
    "        r = '[a-z]+-(\\d{4})'\n",
    "        onlyfiles = [f for f in os.listdir(\"data/downloaded\") if os.path.isfile(os.path.join(\"data/downloaded\", f)) and os.path.join(\"data/downloaded\", f)[-5] == \"A\"]\n",
    "        return [f for f in onlyfiles if f not in [\"twitter-2016dev-A.tsv\", \"twitter-2016devtest-A.tsv\", \"twitter-2016train-A.tsv\"]]\n",
    "    return [\"twitter-2016dev-A.tsv\", \"twitter-2016devtest-A.tsv\", \"twitter-2016train-A.tsv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_data(dataset: Literal[\"train\",\"test\"], path=\"data/downloaded/\") -> None:\n",
    "    # write all data from previous years to new file, as in paper\n",
    "    filenames = get_filenames(dataset, path=path)\n",
    "\n",
    "    with codecs.open(f'{path}twitter-{dataset}.tsv','w', encoding=\"utf-8\") as outfile:\n",
    "        for fname in filenames:\n",
    "            with codecs.open(path+fname, \"r\",encoding=\"utf-8\") as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(\"train\")\n",
    "concatenate_data(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 80%, test: 20%\n",
      "train: 40297, test: 9834\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv(\"data/downloaded/twitter-train.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"],encoding=\"utf-8\")\n",
    "# test = pd.read_csv(\"data/downloaded/twitter-test.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"],encoding=\"utf-8\")\n",
    "# # dev = pd.read_csv(\"data/downloaded/twitter-2016dev-A.tsv\", sep='\\t', usecols=[1,2], names=[\"label\", \"text\"])\n",
    "\n",
    "# print(f\"train: {round(train.shape[0]/(train.shape[0]+test.shape[0])*100)}%, test: {round(test.shape[0]/(train.shape[0]+test.shape[0])*100)}%\")\n",
    "# print(f\"train: {train.shape[0]}, test: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 80%, test: 20%\n",
      "train: 40280, test: 9827\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/bert_tokenized/bert_train_data.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"data/bert_tokenized/bert_test_data.pkl\",\"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "print(f\"train: {round(train.shape[0]/(train.shape[0]+test.shape[0])*100)}%, test: {round(test.shape[0]/(train.shape[0]+test.shape[0])*100)}%\")\n",
    "print(f\"train: {train.shape[0]}, test: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6242</td>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19096</td>\n",
       "      <td>3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>14959</td>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "label                \n",
       "negative   6242  1566\n",
       "neutral   19096  3425\n",
       "positive  14959  4836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_counts = train.groupby('label').count().rename({\"text\":\"train\"}, axis=1)\n",
    "test_class_counts = test.groupby('label').count().rename({\"text\":\"test\"}, axis=1)\n",
    "# dev_class_counts = dev.groupby('label').count().rename({\"text\":\"dev\"}, axis=1)\n",
    "\n",
    "#TODO we moeten nog dev hebben: 80/20 split van tex\n",
    "\n",
    "\n",
    "pd.concat([train_class_counts, test_class_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing:\n",
    "remove links? \n",
    "remove @'s ?\n",
    "punctuation etc? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0   neutral  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
       "1   neutral  Order Go Set a Watchman in store or through ou...\n",
       "2  negative  If these runway renovations at the airport pre...\n",
       "3   neutral  If you could ask an onstage interview question...\n",
       "4  positive  A portion of book sales from our Harper Lee/Go..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing:\n",
    "\n",
    "def preprocess(data: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "        \n",
    "    # remove urls\n",
    "    data_clean = data.copy()\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'https?:\\/\\/t\\.co\\/\\w+','',x))\n",
    "\n",
    "    # remove emailadresses\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'\\w+@\\w+\\.[a-z]+','',x))\n",
    "\n",
    "    # remove html ref\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'&amp', '&', x))\n",
    "\n",
    "    # remove unicode\n",
    "    # data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'\\\\u[a-z0-9]{4}', '', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(\"RT : \", '',x))\n",
    "\n",
    "    # remove all @ mention\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "\n",
    "    # remove non-letter characters, numbers \n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"[^a-zA-Z\\s\\:\\];='\\.\\!\\?\\,]\", '', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])st([.,!?\\s])\", r'\\1\\2', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])th([.,!?\\s])\", r'\\1\\2', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])nd([.,!?\\s])\", r'\\1\\2', x))\n",
    "    data_clean['text']=data_clean.text.apply(lambda x: re.sub(r\"([.,!?\\s])rd([.,!?\\s])\", r'\\1\\2', x))\n",
    "\n",
    "\n",
    "    # remove trailing whitespace\n",
    "    # data_clean['text']=data_clean.text.apply(lambda x: re.sub(r'[\\t \\v]+', '', x).strip())\n",
    "\n",
    "    data_clean.to_csv(f\"data/downloaded/twitter-{name}-clean.tsv\", sep=\"\\t\", index=False,header=False,encoding=\"utf-8\")\n",
    "\n",
    "    return data_clean\n",
    "# overige dingen: afkortingen? getallen kunnen belangrijk zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = preprocess(train, \"train\")\n",
    "test_cleaned = preprocess(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit .!!!! Ium going to Chapel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shituc watch Rafa and Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that Ium a GSP fanuc i just hate Nick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israelus Iron Dome canut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehranuc Mon Amour: Obama Tried to Establish T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  positive  Gas by my house hit .!!!! Ium going to Chapel ...\n",
       "1  negative  Theo Walcott is still shituc watch Rafa and Jo...\n",
       "2  negative  its not that Ium a GSP fanuc i just hate Nick ...\n",
       "3  negative  Iranian general says Israelus Iron Dome canut ...\n",
       "4   neutral  Tehranuc Mon Amour: Obama Tried to Establish T..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat + flatten\n",
    "import re\n",
    "import string\n",
    "all_data = pd.concat([train,test])\n",
    "terms = []\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "\n",
    "for index, row in all_data.iterrows():\n",
    "    tweet = row.text.lower()\n",
    "    terms.extend(regex.sub('',tweet).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906705"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace = ['', \" \", \"\\t\", \"\\n\"]\n",
    "terms_cleaned = [t for t in terms if t not in whitespace]\n",
    "len(terms_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gas',\n",
       " 'by',\n",
       " 'my',\n",
       " 'house',\n",
       " 'hit',\n",
       " 'ium',\n",
       " 'going',\n",
       " 'to',\n",
       " 'chapel',\n",
       " 'hill',\n",
       " 'on',\n",
       " 'sat',\n",
       " 'theo',\n",
       " 'walcott',\n",
       " 'is',\n",
       " 'still',\n",
       " 'shituc',\n",
       " 'watch',\n",
       " 'rafa',\n",
       " 'and',\n",
       " 'johnny',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'him',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'its',\n",
       " 'not',\n",
       " 'that',\n",
       " 'ium',\n",
       " 'a',\n",
       " 'gsp',\n",
       " 'fanuc',\n",
       " 'i',\n",
       " 'just',\n",
       " 'hate',\n",
       " 'nick',\n",
       " 'diaz',\n",
       " 'canut',\n",
       " 'wait',\n",
       " 'for',\n",
       " 'february',\n",
       " 'iranian',\n",
       " 'general',\n",
       " 'says',\n",
       " 'israelus',\n",
       " 'iron',\n",
       " 'dome',\n",
       " 'canut',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'their',\n",
       " 'missiles',\n",
       " 'keep',\n",
       " 'talking',\n",
       " 'like',\n",
       " 'that',\n",
       " 'and',\n",
       " 'we',\n",
       " 'may',\n",
       " 'end',\n",
       " 'up',\n",
       " 'finding',\n",
       " 'out',\n",
       " 'tehranuc',\n",
       " 'mon',\n",
       " 'amour',\n",
       " 'obama',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'establish',\n",
       " 'ties',\n",
       " 'with',\n",
       " 'the',\n",
       " 'mullahs',\n",
       " 'via',\n",
       " 'no',\n",
       " 'barack',\n",
       " 'obama',\n",
       " 'vote',\n",
       " 'mitt',\n",
       " 'romney',\n",
       " 'i',\n",
       " 'sat',\n",
       " 'through',\n",
       " 'this',\n",
       " 'whole',\n",
       " 'movie',\n",
       " 'just',\n",
       " 'for',\n",
       " 'harry',\n",
       " 'and',\n",
       " 'ron',\n",
       " 'at',\n",
       " 'christmas',\n",
       " 'ohlawd',\n",
       " 'with',\n",
       " 'j',\n",
       " 'davlar',\n",
       " 'main',\n",
       " 'rivals',\n",
       " 'are',\n",
       " 'team',\n",
       " 'poland',\n",
       " 'hopefully',\n",
       " 'we',\n",
       " 'an',\n",
       " 'make',\n",
       " 'it',\n",
       " 'a',\n",
       " 'successful',\n",
       " 'end',\n",
       " 'to',\n",
       " 'a',\n",
       " 'tough',\n",
       " 'week',\n",
       " 'of',\n",
       " 'training',\n",
       " 'tomorrow',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'actus',\n",
       " 'satusuc',\n",
       " 'deciding',\n",
       " 'where',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'collegeuc',\n",
       " 'applying',\n",
       " 'to',\n",
       " 'colleges',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'about',\n",
       " 'college',\n",
       " 'stresses',\n",
       " 'me',\n",
       " 'out',\n",
       " 'why',\n",
       " 'is',\n",
       " 'happy',\n",
       " 'valentines',\n",
       " 'day',\n",
       " 'trending',\n",
       " 'itus',\n",
       " 'on',\n",
       " 'the',\n",
       " 'of',\n",
       " 'february',\n",
       " 'not',\n",
       " 'of',\n",
       " 'june',\n",
       " 'smh',\n",
       " 'they',\n",
       " 'may',\n",
       " 'have',\n",
       " 'a',\n",
       " 'superbowl',\n",
       " 'in',\n",
       " 'dallasuc',\n",
       " 'but',\n",
       " 'dallas',\n",
       " 'ainut',\n",
       " 'winning',\n",
       " 'a',\n",
       " 'superbowl',\n",
       " 'not',\n",
       " 'with',\n",
       " 'that',\n",
       " 'quarterback',\n",
       " 'and',\n",
       " 'owner',\n",
       " 'im',\n",
       " 'bringing',\n",
       " 'the',\n",
       " 'monster',\n",
       " 'load',\n",
       " 'of',\n",
       " 'candy',\n",
       " 'tomorrowuc',\n",
       " 'i',\n",
       " 'just',\n",
       " 'hope',\n",
       " 'it',\n",
       " 'doesnut',\n",
       " 'get',\n",
       " 'all',\n",
       " 'squiched',\n",
       " 'apple',\n",
       " 'softwareuc',\n",
       " 'retail',\n",
       " 'chiefs',\n",
       " 'out',\n",
       " 'in',\n",
       " 'overhaul',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'apple',\n",
       " 'inc',\n",
       " 'ceo',\n",
       " 'tim',\n",
       " 'cook',\n",
       " 'on',\n",
       " 'monday',\n",
       " 'replaced',\n",
       " 'the',\n",
       " 'heads',\n",
       " 'i',\n",
       " 'just',\n",
       " 'watched',\n",
       " 'it',\n",
       " 'sridevius',\n",
       " 'comeback',\n",
       " 'u',\n",
       " 'remember',\n",
       " 'her',\n",
       " 'from',\n",
       " 'the',\n",
       " 's',\n",
       " 'sun',\n",
       " 'mornings',\n",
       " 'on',\n",
       " 'nta',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'best',\n",
       " 'graders',\n",
       " 'kory',\n",
       " 'was',\n",
       " 'excited',\n",
       " 'after',\n",
       " 'his',\n",
       " 'touchdown',\n",
       " 'today',\n",
       " 'he',\n",
       " 'did',\n",
       " 'the',\n",
       " 'victor',\n",
       " 'cruzlol',\n",
       " 'livewire',\n",
       " 'nadal',\n",
       " 'confirmed',\n",
       " 'for',\n",
       " 'mexican',\n",
       " 'open',\n",
       " 'in',\n",
       " 'february',\n",
       " 'rafael',\n",
       " 'nadal',\n",
       " 'is',\n",
       " 'set',\n",
       " 'to',\n",
       " 'play',\n",
       " 'at',\n",
       " 'the',\n",
       " 'me',\n",
       " 'livewireathletics',\n",
       " 'i',\n",
       " 'didnt',\n",
       " 'want',\n",
       " 'to',\n",
       " 'just',\n",
       " 'pop',\n",
       " 'up',\n",
       " 'but',\n",
       " 'yep',\n",
       " 'we',\n",
       " 'have',\n",
       " 'chapel',\n",
       " 'hill',\n",
       " 'next',\n",
       " 'wednesday',\n",
       " 'you',\n",
       " 'should',\n",
       " 'come',\n",
       " 'and',\n",
       " 'shes',\n",
       " 'great',\n",
       " 'ill',\n",
       " 'tell',\n",
       " 'her',\n",
       " 'you',\n",
       " 'asked',\n",
       " 'hmmmm',\n",
       " 'november',\n",
       " 'is',\n",
       " 'an',\n",
       " 'odd',\n",
       " 'release',\n",
       " 'date',\n",
       " 'if',\n",
       " 'true',\n",
       " 'but',\n",
       " 'if',\n",
       " 'it',\n",
       " 'becomes',\n",
       " 'big',\n",
       " 'enough',\n",
       " 'maybe',\n",
       " 'she',\n",
       " 'could',\n",
       " 'sing',\n",
       " 'it',\n",
       " 'at',\n",
       " 'grammys',\n",
       " 'iran',\n",
       " 'us',\n",
       " 'delisting',\n",
       " 'mko',\n",
       " 'from',\n",
       " 'global',\n",
       " 'terrorists',\n",
       " 'list',\n",
       " 'in',\n",
       " 'line',\n",
       " 'with',\n",
       " 'iran',\n",
       " 'campaign',\n",
       " 'tehranuc',\n",
       " 'oct',\n",
       " 'uc',\n",
       " 'irna',\n",
       " 'secretary',\n",
       " 'serge',\n",
       " 'is',\n",
       " 'amazing',\n",
       " 'like',\n",
       " 'hes',\n",
       " 'actually',\n",
       " 'a',\n",
       " 'god',\n",
       " 'the',\n",
       " 'lanky',\n",
       " 'sex',\n",
       " 'god',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'kasabian',\n",
       " 'and',\n",
       " 'noel',\n",
       " 'together',\n",
       " 'in',\n",
       " 'august',\n",
       " 'it',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'larry',\n",
       " 'bird',\n",
       " 'is',\n",
       " 'ranked',\n",
       " 'alltime',\n",
       " 'not',\n",
       " 'including',\n",
       " 'lebron',\n",
       " 'or',\n",
       " 'kobe',\n",
       " 'just',\n",
       " 'sayin',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'becky',\n",
       " 'thursday',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'fantastic',\n",
       " 'expect',\n",
       " 'lightmoderate',\n",
       " 'rains',\n",
       " 'over',\n",
       " 'e',\n",
       " 'visayas',\n",
       " 'cebuuc',\n",
       " 'boholuc',\n",
       " 'samar',\n",
       " 'leyte',\n",
       " 'have',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'rains',\n",
       " 'tonight',\n",
       " 'expect',\n",
       " 'fair',\n",
       " 'weather',\n",
       " 'tomorrow',\n",
       " 'one',\n",
       " 'ticket',\n",
       " 'left',\n",
       " 'for',\n",
       " 'the',\n",
       " 'game',\n",
       " 'tomorrow',\n",
       " 'donut',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'rematch',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nfc',\n",
       " 'championship',\n",
       " 'game',\n",
       " 'against',\n",
       " 'the',\n",
       " 'ny',\n",
       " 'giants',\n",
       " 'hit',\n",
       " 'me',\n",
       " 'up',\n",
       " 'afc',\n",
       " 'away',\n",
       " 'fans',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'about',\n",
       " 'the',\n",
       " 'ushe',\n",
       " 'said',\n",
       " 'nou',\n",
       " 'chant',\n",
       " 'itus',\n",
       " 'bollocks',\n",
       " 'when',\n",
       " 'he',\n",
       " 'has',\n",
       " 'the',\n",
       " 'balluc',\n",
       " 'just',\n",
       " 'turn',\n",
       " 'your',\n",
       " 'back',\n",
       " 'on',\n",
       " 'him',\n",
       " 'my',\n",
       " 'saturday',\n",
       " 'night',\n",
       " 'has',\n",
       " 'consisted',\n",
       " 'of',\n",
       " 'me',\n",
       " 'watching',\n",
       " 'the',\n",
       " 'grey',\n",
       " 'with',\n",
       " 'my',\n",
       " 'puppy',\n",
       " 'while',\n",
       " 'my',\n",
       " 'parents',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'rager',\n",
       " 'whaa',\n",
       " 'liamneesonisbosstho',\n",
       " 'why',\n",
       " 'is',\n",
       " 'it',\n",
       " 'so',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'find',\n",
       " 'the',\n",
       " 'these',\n",
       " 'days',\n",
       " 'went',\n",
       " 'to',\n",
       " 'stores',\n",
       " 'for',\n",
       " 'the',\n",
       " 'castle',\n",
       " 'cover',\n",
       " 'issue',\n",
       " 'none',\n",
       " 'will',\n",
       " 'search',\n",
       " 'again',\n",
       " 'tomorrow',\n",
       " 'game',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nlcs',\n",
       " 'and',\n",
       " 'a',\n",
       " 'rematch',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nfc',\n",
       " 'championship',\n",
       " 'game',\n",
       " 'tomorrow',\n",
       " 'sfus',\n",
       " 'gonna',\n",
       " 'be',\n",
       " 'cuuuuhraaaaaaaazeeeee',\n",
       " 'james',\n",
       " 'hall',\n",
       " 'live',\n",
       " 'in',\n",
       " 'indianapolis',\n",
       " 'dec',\n",
       " 'christ',\n",
       " 'church',\n",
       " 'apostolicu',\n",
       " 'tixs',\n",
       " 'just',\n",
       " 'adv',\n",
       " 'be',\n",
       " 'there',\n",
       " 'the',\n",
       " 'heat',\n",
       " 'game',\n",
       " 'may',\n",
       " 'cost',\n",
       " 'alot',\n",
       " 'moreand',\n",
       " 'plus',\n",
       " 'i',\n",
       " 'would',\n",
       " 'rather',\n",
       " 'see',\n",
       " 'austin',\n",
       " 'rivers',\n",
       " 'play',\n",
       " 'never',\n",
       " 'start',\n",
       " 'working',\n",
       " 'on',\n",
       " 'your',\n",
       " 'dreams',\n",
       " 'and',\n",
       " 'goals',\n",
       " 'tomorrowtomorrow',\n",
       " 'never',\n",
       " 'comesif',\n",
       " 'it',\n",
       " 'means',\n",
       " 'anything',\n",
       " 'to',\n",
       " 'uuc',\n",
       " 'act',\n",
       " 'now',\n",
       " 'getafterit',\n",
       " 'i',\n",
       " 'had',\n",
       " 'vick',\n",
       " 'and',\n",
       " 'flaccouc',\n",
       " 'needed',\n",
       " 'an',\n",
       " 'upgrade',\n",
       " 'vick',\n",
       " 'may',\n",
       " 'get',\n",
       " 'bencheduc',\n",
       " 'jennings',\n",
       " 'a',\n",
       " 'back',\n",
       " 'up',\n",
       " 'again',\n",
       " 'soon',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'win',\n",
       " 'for',\n",
       " 'me',\n",
       " 'key',\n",
       " 'largouc',\n",
       " 'fl',\n",
       " 'yay',\n",
       " 'just',\n",
       " 'ur',\n",
       " 'neighbor',\n",
       " 'lisa',\n",
       " 'a',\n",
       " 'sip',\n",
       " 'n',\n",
       " 'a',\n",
       " 'hop',\n",
       " 'away',\n",
       " 'always',\n",
       " 'watching',\n",
       " 'rhom',\n",
       " 'thurus',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'andy',\n",
       " 'the',\n",
       " 'android',\n",
       " 'may',\n",
       " 'have',\n",
       " 'had',\n",
       " 'a',\n",
       " 'little',\n",
       " 'too',\n",
       " 'much',\n",
       " 'fun',\n",
       " 'yesterday',\n",
       " 'oooh',\n",
       " 'nice',\n",
       " 'tis',\n",
       " 'tempting',\n",
       " 'to',\n",
       " 'go',\n",
       " 'up',\n",
       " 'the',\n",
       " 'lakes',\n",
       " 'with',\n",
       " 'my',\n",
       " 'nikon',\n",
       " 'hmmmm',\n",
       " 'i',\n",
       " 'may',\n",
       " 'do',\n",
       " 'that',\n",
       " 'black',\n",
       " 'friday',\n",
       " 'huge',\n",
       " 'saving',\n",
       " 'aerial',\n",
       " 'view',\n",
       " 'of',\n",
       " 'a',\n",
       " 'cityuc',\n",
       " 'paris',\n",
       " 'las',\n",
       " 'vegasuc',\n",
       " 'the',\n",
       " 'las',\n",
       " 'vegas',\n",
       " 'stripuc',\n",
       " 'las',\n",
       " 'vegasuc',\n",
       " 'yes',\n",
       " 'we',\n",
       " 'all',\n",
       " 'know',\n",
       " 'indio',\n",
       " 'vs',\n",
       " 'cv',\n",
       " 'is',\n",
       " 'tomorrow',\n",
       " 'the',\n",
       " 'bell',\n",
       " 'game',\n",
       " 'its',\n",
       " 'enough',\n",
       " 'jenelle',\n",
       " 'liesucst',\n",
       " 'she',\n",
       " 'said',\n",
       " 'she',\n",
       " 'was',\n",
       " 'alone',\n",
       " 'the',\n",
       " 'hospnow',\n",
       " 'sheus',\n",
       " 'saying',\n",
       " 'how',\n",
       " 'weird',\n",
       " 'it',\n",
       " 'was',\n",
       " 'for',\n",
       " 'keifferus',\n",
       " 'lmfao',\n",
       " 'his',\n",
       " 'big',\n",
       " 'ass',\n",
       " 'get',\n",
       " 'on',\n",
       " 'my',\n",
       " 'nervesuc',\n",
       " 'you',\n",
       " 'going',\n",
       " 'to',\n",
       " 'class',\n",
       " 'tomorrow',\n",
       " 'ium',\n",
       " 'going',\n",
       " 'to',\n",
       " 'hong',\n",
       " 'kong',\n",
       " 'during',\n",
       " 'that',\n",
       " 'time',\n",
       " 'and',\n",
       " 'mama',\n",
       " 'is',\n",
       " 'on',\n",
       " 'nov',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'them',\n",
       " 'live',\n",
       " 'happy',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'nick',\n",
       " 'j',\n",
       " 'forever',\n",
       " 'off',\n",
       " 'the',\n",
       " 'chain',\n",
       " 'dream',\n",
       " 'high',\n",
       " 'sucks',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'the',\n",
       " 'one',\n",
       " 'mohamed',\n",
       " 'morsiuc',\n",
       " 'egyptus',\n",
       " 'muslim',\n",
       " 'brotherhood',\n",
       " 'presidentuc',\n",
       " 'instructed',\n",
       " 'the',\n",
       " 'supreme',\n",
       " 'council',\n",
       " 'of',\n",
       " 'the',\n",
       " 'armed',\n",
       " 'forces',\n",
       " 'thursday',\n",
       " 'cumon',\n",
       " 'avila',\n",
       " 'you',\n",
       " 'just',\n",
       " 'got',\n",
       " 'tagged',\n",
       " 'out',\n",
       " 'by',\n",
       " 'a',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'the',\n",
       " 'kid',\n",
       " 'bill',\n",
       " 'murray',\n",
       " 'was',\n",
       " 'researching',\n",
       " 'in',\n",
       " 'the',\n",
       " 'royal',\n",
       " 'tenenbaums',\n",
       " 'tigers',\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'boro',\n",
       " 'will',\n",
       " 'beat',\n",
       " 'swansea',\n",
       " 'ium',\n",
       " 'not',\n",
       " 'so',\n",
       " 'sureuc',\n",
       " 'decemberjanuary',\n",
       " 'is',\n",
       " 'when',\n",
       " 'we',\n",
       " 'implode',\n",
       " 'at',\n",
       " 'the',\n",
       " 'first',\n",
       " 'grammy',\n",
       " 'awardsuc',\n",
       " 'held',\n",
       " 'on',\n",
       " 'may',\n",
       " 'uc',\n",
       " 'domenico',\n",
       " 'modugno',\n",
       " 'beat',\n",
       " 'out',\n",
       " 'frank',\n",
       " 'sinatra',\n",
       " 'and',\n",
       " 'peggy',\n",
       " 'lee',\n",
       " 'for',\n",
       " 'the',\n",
       " 'record',\n",
       " 'of',\n",
       " 'the',\n",
       " 'yearucwith',\n",
       " 'volare',\n",
       " 'happy',\n",
       " 'birthday',\n",
       " 'vow',\n",
       " 'the',\n",
       " 'anniversary',\n",
       " 'i',\n",
       " 'have',\n",
       " 'studied',\n",
       " 'all',\n",
       " 'day',\n",
       " 'but',\n",
       " 'tomorrow',\n",
       " 'ium',\n",
       " 'going',\n",
       " 'out',\n",
       " 'with',\n",
       " 'friends',\n",
       " 'd',\n",
       " 'omg',\n",
       " 'jennette',\n",
       " 'did',\n",
       " 'ium',\n",
       " 'gonna',\n",
       " 'look',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'thursday',\n",
       " 'life',\n",
       " 'is',\n",
       " 'fragile',\n",
       " 'weure',\n",
       " 'not',\n",
       " 'guaranteed',\n",
       " 'a',\n",
       " 'tomorrow',\n",
       " 'so',\n",
       " 'give',\n",
       " 'it',\n",
       " 'everything',\n",
       " 'youuve',\n",
       " 'got',\n",
       " 'tim',\n",
       " 'cook',\n",
       " 'do',\n",
       " 'it',\n",
       " 'for',\n",
       " 'jobs',\n",
       " 'twitition',\n",
       " 'mcfly',\n",
       " 'come',\n",
       " 'back',\n",
       " 'to',\n",
       " 'argentina',\n",
       " 'but',\n",
       " 'this',\n",
       " 'time',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'mar',\n",
       " 'del',\n",
       " 'plata',\n",
       " 'anything',\n",
       " 'i',\n",
       " 'wondered',\n",
       " 'how',\n",
       " 'the',\n",
       " 'aspects',\n",
       " 'btwn',\n",
       " 'my',\n",
       " 'sunmoon',\n",
       " 'faired',\n",
       " 'with',\n",
       " 'my',\n",
       " 'rising',\n",
       " 'i',\n",
       " 'also',\n",
       " 'have',\n",
       " 'venus',\n",
       " 'in',\n",
       " 'sagyea',\n",
       " 'lol',\n",
       " 'thank',\n",
       " 'u',\n",
       " 'my',\n",
       " 'teachers',\n",
       " 'call',\n",
       " 'themselves',\n",
       " 'givng',\n",
       " 'us',\n",
       " 'candywasnut',\n",
       " 'even',\n",
       " 'the',\n",
       " 'good',\n",
       " 'stuff',\n",
       " 'i',\n",
       " 'might',\n",
       " 'go',\n",
       " 'to',\n",
       " 'walmart',\n",
       " 'or',\n",
       " 'cvs',\n",
       " 'tomorrow',\n",
       " 'broncos',\n",
       " 'peyton',\n",
       " 'manning',\n",
       " 'named',\n",
       " 'afc',\n",
       " 'offensive',\n",
       " 'player',\n",
       " 'of',\n",
       " 'the',\n",
       " 'month',\n",
       " 'itus',\n",
       " 'his',\n",
       " 'such',\n",
       " 'honoruc',\n",
       " 'second',\n",
       " 'to',\n",
       " 'tom',\n",
       " 'bradyus',\n",
       " 'uc',\n",
       " 'tied',\n",
       " 'w',\n",
       " 'td',\n",
       " 'is',\n",
       " 'bringing',\n",
       " 'out',\n",
       " 'kendrick',\n",
       " 'lamar',\n",
       " 'the',\n",
       " 'of',\n",
       " 'december',\n",
       " 'get',\n",
       " 'your',\n",
       " 'tickets',\n",
       " 'now',\n",
       " 'i',\n",
       " 'may',\n",
       " 'have',\n",
       " 'an',\n",
       " 'android',\n",
       " 'phone',\n",
       " 'by',\n",
       " 'the',\n",
       " 'time',\n",
       " 'i',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'school',\n",
       " 'andreus',\n",
       " 'wigan',\n",
       " 'warning',\n",
       " 'coys',\n",
       " 'official',\n",
       " 'site',\n",
       " 'wigan',\n",
       " 'might',\n",
       " 'currently',\n",
       " 'occupy',\n",
       " 'place',\n",
       " 'in',\n",
       " 'the',\n",
       " 'premier',\n",
       " 'leagueuc',\n",
       " 'tryst',\n",
       " 'tonight',\n",
       " 'best',\n",
       " 'industrylocalthursday',\n",
       " 'party',\n",
       " 'in',\n",
       " 'las',\n",
       " 'vegas',\n",
       " 'what',\n",
       " 'if',\n",
       " 'it',\n",
       " 'rained',\n",
       " 'we',\n",
       " 'didnut',\n",
       " 'care',\n",
       " 'she',\n",
       " 'said',\n",
       " 'that',\n",
       " 'someday',\n",
       " 'soon',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'was',\n",
       " 'gonna',\n",
       " 'shine',\n",
       " 'and',\n",
       " 'she',\n",
       " 'was',\n",
       " 'right',\n",
       " 'this',\n",
       " 'love',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40339/157955553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtop10000_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcount_tuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop10000_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmost_common_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmost_common_terms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_40339/157955553.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtop10000_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcount_tuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop10000_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmost_common_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmost_common_terms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "top10000_counts = Counter(terms_cleaned[:10000]).most_common()\n",
    "words = [count_tuple[0] for count_tuple in top10000_counts]\n",
    "most_common_terms = [t for t in terms if t in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'to', 'i', 'on', 'a', 'in', 'and', 'for', 'of', 'is']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7b48cf7c021d35b2fd1684e6f7d2f969b0897b100551e75462f6bc010a51b9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tmprojectenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
